{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e69f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md\n",
    "!pip install openpyxl\n",
    "!pip install transformers\n",
    "!pip install gensim==3.8.3\n",
    "!pip install numpy==1.22.0\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ee110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from preprocessor import Preprocessing\n",
    "\n",
    "\n",
    "preprocessor = Preprocessing()\n",
    "\n",
    "conservative_df = pd.concat([pd.read_csv('cons_comments.csv', header=0), pd.read_csv('rep_comments.csv', header=0)]).sample(10)\n",
    "conservative_df['preprocess_body'] = conservative_df['body'].apply(preprocessor.pre_process_text)\n",
    "conservative_df['num_sentences'] = conservative_df['body'].apply(preprocessor.get_num_sentences)\n",
    "conservative_df['numWords'] = conservative_df['body'].apply(preprocessor.get_num_words)\n",
    "conservative_df.to_csv('conservative_metadata_and_preprocessed_with_stop_words.csv', index = False)\n",
    "\n",
    "liberal_df = pd.concat([pd.read_excel('lib_comments.xlsx', header=0), pd.read_excel('dem_comments.xlsx', header=0)]).sample(10)\n",
    "liberal_df['preprocess_body'] = liberal_df['body'].apply(preprocessor.pre_process_text)\n",
    "liberal_df['num_sentences'] = liberal_df['body'].apply(preprocessor.get_num_sentences)\n",
    "liberal_df['numWords'] = liberal_df['body'].apply(preprocessor.get_num_words)\n",
    "liberal_df.to_csv('liberal_metadata_and_preprocessed_with_stop_words.csv', index = False)\n",
    "\n",
    "conservative_base_sample_df =  pd.read_csv('conservative_metadata_and_preprocessed_with_stop_words.csv', header=0).sample(n=194944)\n",
    "liberal_base_sample_df =  pd.read_csv('liberal_metadata_and_preprocessed_with_stop_words.csv', header=0).sample(n=194944)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fbb0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_vocab = preprocessor.create_vocab(conservative_base_sample_df['preprocess_body'])\n",
    "liberal_vocab = preprocessor.create_vocab(liberal_base_sample_df['preprocess_body'])\n",
    "\n",
    "common_vocab = preprocessor.find_common_vocab(conservative_vocab, liberal_vocab)\n",
    "conservative_vocab_percent = len(conservative_vocab) / len(common_vocab) * 100\n",
    "liberal_vocab_percent = len(liberal_vocab) / len(common_vocab) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4abe507-015a-43c3-85b5-2d2c42105b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = ['conservative', 'liberal']\n",
    "colors = ['red', 'blue']\n",
    "size = [len(conservative_base_sample_df['body']), len(liberal_base_sample_df['body'])]\n",
    "vocab_percent = [conservative_vocab_percent , liberal_vocab_percent]\n",
    "vocab_size = [len(conservative_vocab), len(liberal_vocab)]\n",
    "average_sent_length = [np.mean(conservative_base_sample_df['num_sentences']), np.mean(liberal_base_sample_df['num_sentences'])]\n",
    "average_word_count = [np.mean(conservative_base_sample_df['numWords']), np.mean(liberal_base_sample_df['numWords'])]\n",
    "\n",
    "# post size\n",
    "plt.bar(x, size, color=colors)\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Posts')\n",
    "plt.title('Reddit Posts size comparison')\n",
    "for i, v in enumerate(size):\n",
    "    plt.text(i, v + 1, str(v), color='black', fontweight='bold', ha='center')\n",
    "plt.gcf().set_size_inches(6, 4) # set the figure size to 6 inches wide by 4 inches high\n",
    "plt.subplots_adjust(left=0.15)\n",
    "plt.show()\n",
    "\n",
    "# vocabulary distribution\n",
    "chart = plt.pie(vocab_percent, labels=x, autopct='%1.1f%%', colors=colors)\n",
    "plt.title('Vocabulary Distribution')\n",
    "legend_labels = []\n",
    "for i in range(len(vocab_size)):\n",
    "    legend_labels.append(f\"{x[i]}: {vocab_size[i]}\")\n",
    "plt.legend(chart[0], legend_labels, title='Category', loc='center left')\n",
    "plt.show()\n",
    "\n",
    "# Sentence length\n",
    "plt.barh(x, average_sent_length, color=colors)\n",
    "plt.xlabel('Number of sentences per post')\n",
    "plt.ylabel('Category')\n",
    "plt.title('Average Sentences per Post')\n",
    "for i, v in enumerate(average_sent_length):\n",
    "    plt.text(v + 0.3, i, str(round(v, 2)), color='black', fontweight='bold', ha='center')\n",
    "plt.show()\n",
    "\n",
    "# Number of words\n",
    "plt.scatter(x, average_word_count, s=[a * 25 for a in average_word_count], alpha=0.5, c=colors, cmap='viridis')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of words per post')\n",
    "plt.title('Average word count')\n",
    "for i, v in enumerate(average_word_count):\n",
    "    plt.text(i, v, str(int(v)), color='black', fontweight='bold', ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c0fae-76ba-4a56-a4c5-bce1495fd922",
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_words = preprocessor.get_meta_data(conservative_base_sample_df).sort_values('score', ascending = False)[\"word\"].head(100)\n",
    "liberal_words = preprocessor.get_meta_data(liberal_base_sample_df).sort_values('score', ascending = False)[\"word\"].head(100)\n",
    "intersection = set(conservative_words).intersection(set(liberal_words))\n",
    "print(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c83981-7901-4575-87d9-30c480004676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "words_of_interest = [\n",
    "    \"conservative\",\n",
    "    \"trump\",\n",
    "    \"democrat\",\n",
    "    \"election\",\n",
    "    \"party\",\n",
    "    \"job\",\n",
    "    \"news\",\n",
    "    \"vote\",\n",
    "    \"president\",\n",
    "    \"american\",\n",
    "    \"right\",\n",
    "    \"pay\",\n",
    "    \"run\",\n",
    "    \"government\",\n",
    "    \"country\",\n",
    "    \"democrats\",\n",
    "    \"bernie\",\n",
    "    \"biden\",\n",
    "    \"state\",\n",
    "    \"life\",\n",
    "    \"support\",\n",
    "]\n",
    "\n",
    "similar_sentences_group = {}\n",
    "\n",
    "conservative_metadata = preprocessor.get_meta_data(conservative_base_sample_df)\n",
    "liberal_metadata = preprocessor.get_meta_data(liberal_base_sample_df)\n",
    "\n",
    "for word in words_of_interest:\n",
    "    similar_sentences_group[word] = defaultdict(list)\n",
    "    conservative_docs = list(set([postId \n",
    "                                  for postSet in conservative_metadata[conservative_metadata[\"word\"] == word][\"doc_ids\"]\n",
    "                                  for postId in postSet]\n",
    "                                )\n",
    "                            )\n",
    "    conservative_docs = list(map(lambda x: x.strip(\"'\"), conservative_docs))\n",
    "    for index, row in conservative_base_sample_df[conservative_base_sample_df[\"id\"].isin(conservative_docs)].iterrows():\n",
    "        doc = preprocessor.get_processed_document(row[\"body\"])\n",
    "        similar_sentences_group[word][\"conservative\"].extend([sent for sent in doc.sents])\n",
    "     \n",
    "    \n",
    "    liberal_docs = list(set([postId \n",
    "                             for postSet in liberal_metadata[liberal_metadata[\"word\"] == word][\"doc_ids\"]\n",
    "                             for postId in postSet]\n",
    "                           )\n",
    "                       )\n",
    "    liberal_docs = list(map(lambda x: x.strip(\"'\"), liberal_docs))\n",
    "    for index, row in liberal_base_sample_df[liberal_base_sample_df[\"id\"].isin(liberal_docs)].iterrows():\n",
    "        doc = preprocessor.get_processed_document(row[\"body\"])\n",
    "        similar_sentences_group[word][\"liberal\"].extend([sent for sent in doc.sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d67d28-1e95-4a42-898e-b89976dc2566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from bert_sentence_embeddings import BertSentenceEmbeddings\n",
    "\n",
    "bert_sent_embds = BertSentenceEmbeddings()\n",
    "\n",
    "for word in similar_sentences_group:\n",
    "    conservative_bucket_df = pd.DataFrame({\"sentence\": similar_sentences_group[word][\"conservative\"]})\n",
    "    conservative_bucket_df[\"sentence_processed\"] = conservative_bucket_df[\"sentence\"].apply(bert_sent_embds.preprocess_cosine_similarity)\n",
    "    conservative_final_df = pd.DataFrame(columns=[\"sentence\", \"similar_sentence\", \"cosine_sim_score\"])\n",
    "    for index, row in conservative_bucket_df.iterrows():\n",
    "        similar_sentence, cosine_similarity_score = bert_sent_embds.find_most_similar_document_cosine(conservative_bucket_df[conservative_bucket_df.index != index].reset_index(), row[\"sentence_processed\"])\n",
    "        conservative_final_df = pd.concat([conservative_final_df,\n",
    "                              pd.DataFrame(\n",
    "                                  [(row[\"sentence\"], similar_sentence, cosine_similarity_score)], columns=[\"sentence\", \"similar_sentence\", \"cosine_sim_score\"]\n",
    "                                )\n",
    "                              ]\n",
    "                            )\n",
    "    \n",
    "    liberal_bucket_df = pd.DataFrame({\"sentence\": similar_sentences_group[word][\"liberal\"]})\n",
    "    liberal_bucket_df[\"sentence_processed\"] = liberal_bucket_df[\"sentence\"].apply(bert_sent_embds.preprocess_cosine_similarity)\n",
    "    liberal_final_df = pd.DataFrame(columns=[\"sentence\", \"similar_sentence\", \"cosine_sim_score\"])\n",
    "    for index, row in liberal_bucket_df.iterrows():\n",
    "        similar_sentence, cosine_similarty_score = bert_sent_embds.find_most_similar_document_cosine(liberal_bucket_df[liberal_bucket_df.index != index].reset_index(), row[\"sentence_processed\"])\n",
    "        liberal_final_df = pd.concat([liberal_final_df,\n",
    "                              pd.DataFrame(\n",
    "                                  [(row[\"sentence\"], similar_sentence, cosine_similarty_score)], columns=[\"sentence\", \"similar_sentence\", \"cosine_sim_score\"]\n",
    "                                )\n",
    "                              ]\n",
    "                            )\n",
    "    \n",
    "conservative_final_df.to_csv(\"similar_sents_conservative.csv\",index = False)\n",
    "liberal_final_df.to_csv(\"similar_sents_liberal.csv\", index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b5a72-3c6f-4ed5-9989-27a4b77552ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bert_word_embeddings import BertWordEmbeddings\n",
    "\n",
    "\n",
    "conservative_base_df = pd.read_csv('conservative_base_sample.csv', header=0).sample(100_000)\n",
    "conservative_reddit_posts = [body for body in conservative_base_df[\"body\"] if type(body) == str]\n",
    "bertWordEmbeddings = BertWordEmbeddings(\"ChathuriJ/bert-base-uncased-finetuned-reddit_conservative\")\n",
    "conservative_encodings = bertWordEmbeddings.generate_encodings(conservative_reddit_posts)\n",
    "conservative_word_vector, conservative_word_freq = bertWordEmbeddings.runFFN(conservative_encodings)\n",
    "bertWordEmbeddings.save_pkl(conservative_word_vector, 'conservative_vectors.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23fd7eb-bc39-47f6-b812-5abaf926325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "gensim_model = gensim.models.Word2Vec(\n",
    "    size=768, # size of BERT embeddings\n",
    "    min_count=1,\n",
    "    window=5,\n",
    "    sg=1\n",
    ")\n",
    "gensim_model.build_vocab_from_freq(conservative_word_freq)\n",
    "gensim_model.wv.vectors = np.array([arr for arr in conservative_word_vector.values()])\n",
    "model_path = \"conservative.model\"\n",
    "gensim_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad61206-59e2-4c5c-babd-ebce8833ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bert_word_embeddings import BertWordEmbeddings\n",
    "\n",
    "liberal_base_df = pd.read_csv('liberal_base_sample.csv', header=0).sample(n=100_000)\n",
    "liberal_reddit_posts = [body for body in liberal_base_df[\"body\"] if type(body) == str]\n",
    "bertWordEmbeddings = BertWordEmbeddings(\"ChathuriJ/bert-base-uncased-finetuned-reddit_liberal\")\n",
    "liberal_encodings = bertWordEmbeddings.generate_encodings(liberal_reddit_posts)\n",
    "liberal_word_vector, liberal_word_freq = bertWordEmbeddings.runFFN(liberal_encodings)\n",
    "bertWordEmbeddings.save_pkl(liberal_word_vector, 'liberal_vectors.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3d5f3-94b0-430c-bde7-2fc698a7ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "gensim_model = gensim.models.Word2Vec(\n",
    "    size=768, # size of BERT embeddings\n",
    "    min_count=1,\n",
    "    window=5,\n",
    "    sg=1\n",
    ")\n",
    "gensim_model.build_vocab_from_freq(liberal_word_freq)\n",
    "gensim_model.wv.vectors = np.array([arr for arr in liberal_word_vector.values()])\n",
    "model_path = \"liberal.model\"\n",
    "gensim_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc42b2b4-00b1-494e-aed1-94753d2d1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "most_similar_word_group = {}\n",
    "\n",
    "# word_vectors = bertWordEmbeddings.load_pkl(\"liberal_vectors.pkl\")\n",
    "for key_word in words_of_interest:\n",
    "    if key_word in word_vectors:\n",
    "        # Calculate the cosine similarity between the key word's vector and all other vectors\n",
    "        similarity_scores = cosine_similarity(word_vectors[key_word].reshape(1, -1), list(word_vectors.values()))[0]\n",
    "        # Sort the similarity scores in descending order and get the top 50 words\n",
    "        most_similar_words = [word for _, word in sorted(zip(similarity_scores, word_vectors.keys()), reverse=True)[1:51]]\n",
    "        most_similar_word_group[key_word] = most_similar_words\n",
    "\n",
    "# bertWordEmbeddings.save_pkl(most_similar_word_group, 'liberal_top50_similar_word_groups.pkl')"
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1679199168956,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "nlp-1.2",
   "language": "python",
   "name": "nlp-1.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
