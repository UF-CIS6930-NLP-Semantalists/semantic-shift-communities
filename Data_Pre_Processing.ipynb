{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e69f071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 21:29:17,290 [1368] WARNING  py.warnings:109: [JupyterRequire] /usr/local/lib/python3.9/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_web_sm' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.2.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens.token import Token\n",
    "import string\n",
    "from typing import List\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b74aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_string(data) -> str:\n",
    "    return data if isinstance(data, str) else str(data)\n",
    "\n",
    "def tokenize(text: str) -> List[Token]:\n",
    "  doc = nlp(text) # spacy converts the given text into a list of tokens\n",
    "  return [w for w in doc]\n",
    "\n",
    "def remove_punctuation(tokens: List[Token]) -> List[Token]:\n",
    "  return [t for t in tokens if t.text not in string.punctuation]\n",
    "\n",
    "def remove_stop_words(tokens: List[Token]) -> List[Token]:\n",
    "  return [t for t in tokens if not t.is_stop]\n",
    "\n",
    "def lemmatize(tokens: List[Token]) -> List[str]:\n",
    "  return [t.lemma_ for t in tokens]\n",
    "\n",
    "def pre_process_text(text: str) -> List[str]:\n",
    "    return lemmatize(remove_stop_words(remove_punctuation(tokenize(convert_to_string(text)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ee110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_df = pd.read_csv('/Users/anmol/cis6930-Project/cons_comments.csv', header=0, nrows = 10)\n",
    "liberal_df = pd.read_excel('/Users/anmol/cis6930-Project/lib_comments.xlsx', header=0, nrows = 10)\n",
    "democrat_df = pd.read_excel('/Users/anmol/cis6930-Project/dem_comments.xlsx', header=0, nrows = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a510b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_df['preprocess_body'] = conservative_df['body'].apply(pre_process_text)\n",
    "liberal_df['preprocess_body'] = liberal_df['body'].apply(pre_process_text)\n",
    "democrat_df['preprocess_body'] = democrat_df['body'].apply(pre_process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f793e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(data):\n",
    "    #perform case folding\n",
    "    vocab = {token.lower() for tokens in data for token in tokens}\n",
    "    # create a vocabulary list sorted alphabetically\n",
    "    vocab = sorted(list(vocab))\n",
    "    # assign an index to each word in the vocabulary\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0fbb0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n\\n', ' ', '1.7b', 'administration', 'airliner', 'asset', 'attack', 'away', 'bad', 'beard']\n",
      "['  ', '30', '9/11', 'administration', 'airport', 'area', 'article', 'ass', 'assign', 'ban']\n",
      "['\\n', '\\n\\n', ' \\n\\n', '...', '/u', '30', 'account', 'acknowledge', 'actively', 'actually']\n"
     ]
    }
   ],
   "source": [
    "conservative_vocab = create_vocab(conservative_df['preprocess_body'])\n",
    "liberal_vocab = create_vocab(liberal_df['preprocess_body'])\n",
    "democrat_vocab = create_vocab(democrat_df['preprocess_body'])\n",
    "print(conservative_vocab[:10])\n",
    "print(liberal_vocab[:10])\n",
    "print(democrat_vocab[:10])"
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1679199168956,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
